{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploraci\u00f3n de Modelos YOLO para Detecci\u00f3n de Fracturas en Radiograf\u00edas\n",
    "\n",
    "## Proyecto Final - Deep Learning\n",
    "\n",
    "Este notebook explora el rendimiento de diferentes modelos YOLO con diversos hiperpar\u00e1metros para la identificaci\u00f3n de fracturas en im\u00e1genes de radiograf\u00edas.\n",
    "\n",
    "### Objetivos:\n",
    "1. Comparar diferentes arquitecturas YOLO (YOLOv5, YOLOv8, YOLOv9)\n",
    "2. Evaluar el impacto de diferentes hiperpar\u00e1metros\n",
    "3. Identificar la mejor configuraci\u00f3n para detecci\u00f3n de fracturas\n",
    "4. Visualizar y analizar los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci\u00f3n e Importaci\u00f3n de Librer\u00edas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci\u00f3n de librer\u00edas esenciales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Librer\u00edas para deep learning\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print(\"\u2713 Ultralytics YOLO importado correctamente\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0 Instalar: pip install ultralytics\")\n",
    "\n",
    "# Configuraci\u00f3n de visualizaci\u00f3n\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Librer\u00edas importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definici\u00f3n de Hiperpar\u00e1metros a Explorar\n",
    "\n",
    "Definimos diferentes configuraciones de hiperpar\u00e1metros para evaluar su impacto en el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos YOLO a evaluar\n",
    "modelos = {\n",
    "    'YOLOv5n': 'yolov5n.pt',  # Nano - m\u00e1s r\u00e1pido\n",
    "    'YOLOv5s': 'yolov5s.pt',  # Small\n",
    "    'YOLOv5m': 'yolov5m.pt',  # Medium\n",
    "    'YOLOv8n': 'yolov8n.pt',  # YOLOv8 Nano\n",
    "    'YOLOv8s': 'yolov8s.pt',  # YOLOv8 Small\n",
    "    'YOLOv8m': 'yolov8m.pt',  # YOLOv8 Medium\n",
    "}\n",
    "\n",
    "# Configuraciones de hiperpar\u00e1metros para exploraci\u00f3n\n",
    "hyperparametros_configs = [\n",
    "    {\n",
    "        'nombre': 'Config_1_Baseline',\n",
    "        'epochs': 50,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 0.01,\n",
    "        'optimizer': 'SGD',\n",
    "        'img_size': 640,\n",
    "        'augment': True\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Config_2_LowLR',\n",
    "        'epochs': 50,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 0.001,\n",
    "        'optimizer': 'Adam',\n",
    "        'img_size': 640,\n",
    "        'augment': True\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Config_3_LargeBatch',\n",
    "        'epochs': 50,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 0.01,\n",
    "        'optimizer': 'SGD',\n",
    "        'img_size': 640,\n",
    "        'augment': True\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Config_4_SmallImage',\n",
    "        'epochs': 50,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 0.01,\n",
    "        'optimizer': 'SGD',\n",
    "        'img_size': 416,\n",
    "        'augment': True\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Config_5_LargeImage',\n",
    "        'epochs': 50,\n",
    "        'batch_size': 8,\n",
    "        'learning_rate': 0.01,\n",
    "        'optimizer': 'SGD',\n",
    "        'img_size': 1280,\n",
    "        'augment': True\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Config_6_MoreEpochs',\n",
    "        'epochs': 100,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 0.01,\n",
    "        'optimizer': 'SGD',\n",
    "        'img_size': 640,\n",
    "        'augment': True\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Modelos a evaluar: {len(modelos)}\")\n",
    "print(f\"Configuraciones de hiperpar\u00e1metros: {len(hyperparametros_configs)}\")\n",
    "print(f\"Total de experimentos: {len(modelos) * len(hyperparametros_configs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparaci\u00f3n de Datos\n",
    "\n",
    "Configuraci\u00f3n de rutas y preparaci\u00f3n del dataset de radiograf\u00edas con fracturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas del dataset\n",
    "# NOTA: Actualizar estas rutas seg\u00fan la ubicaci\u00f3n de tus datos\n",
    "DATA_PATH = Path('./data')\n",
    "TRAIN_PATH = DATA_PATH / 'train'\n",
    "VAL_PATH = DATA_PATH / 'val'\n",
    "TEST_PATH = DATA_PATH / 'test'\n",
    "\n",
    "# Archivo de configuraci\u00f3n del dataset para YOLO\n",
    "# Este archivo debe contener las rutas y clases del dataset\n",
    "DATASET_YAML = 'dataset.yaml'\n",
    "\n",
    "# Directorio para guardar resultados\n",
    "RESULTS_PATH = Path('./results')\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Ruta de datos: {DATA_PATH}\")\n",
    "print(f\"Ruta de resultados: {RESULTS_PATH}\")\n",
    "\n",
    "# Verificar estructura de datos (si existen)\n",
    "if DATA_PATH.exists():\n",
    "    print(f\"\\n\u2713 Directorio de datos encontrado\")\n",
    "    print(f\"  - Train: {TRAIN_PATH.exists()}\")\n",
    "    print(f\"  - Val: {VAL_PATH.exists()}\")\n",
    "    print(f\"  - Test: {TEST_PATH.exists()}\")\n",
    "else:\n",
    "    print(f\"\\n\u26a0 Directorio de datos no encontrado. Crear estructura:\")\n",
    "    print(\"  data/\")\n",
    "    print(\"  \u251c\u2500\u2500 train/\")\n",
    "    print(\"  \u2502   \u251c\u2500\u2500 images/\")\n",
    "    print(\"  \u2502   \u2514\u2500\u2500 labels/\")\n",
    "    print(\"  \u251c\u2500\u2500 val/\")\n",
    "    print(\"  \u2502   \u251c\u2500\u2500 images/\")\n",
    "    print(\"  \u2502   \u2514\u2500\u2500 labels/\")\n",
    "    print(\"  \u2514\u2500\u2500 test/\")\n",
    "    print(\"      \u251c\u2500\u2500 images/\")\n",
    "    print(\"      \u2514\u2500\u2500 labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Funci\u00f3n de Entrenamiento y Evaluaci\u00f3n\n",
    "\n",
    "Funci\u00f3n gen\u00e9rica para entrenar modelos YOLO con diferentes configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo(modelo_nombre, modelo_path, config, data_yaml, verbose=False):\n",
    "    \"\"\"\n",
    "    Entrena un modelo YOLO con una configuraci\u00f3n espec\u00edfica de hiperpar\u00e1metros.\n",
    "    \n",
    "    Args:\n",
    "        modelo_nombre: Nombre del modelo (ej: 'YOLOv8s')\n",
    "        modelo_path: Ruta al archivo de pesos pre-entrenados\n",
    "        config: Diccionario con hiperpar\u00e1metros\n",
    "        data_yaml: Ruta al archivo YAML del dataset\n",
    "        verbose: Si mostrar informaci\u00f3n detallada\n",
    "    \n",
    "    Returns:\n",
    "        dict: Resultados del entrenamiento y evaluaci\u00f3n\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Entrenando: {modelo_nombre} con {config['nombre']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Cargar modelo pre-entrenado\n",
    "        model = YOLO(modelo_path)\n",
    "        \n",
    "        # Configurar nombre del experimento\n",
    "        experiment_name = f\"{modelo_nombre}_{config['nombre']}\"\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        results = model.train(\n",
    "            data=data_yaml,\n",
    "            epochs=config['epochs'],\n",
    "            batch=config['batch_size'],\n",
    "            lr0=config['learning_rate'],\n",
    "            optimizer=config['optimizer'],\n",
    "            imgsz=config['img_size'],\n",
    "            augment=config['augment'],\n",
    "            project=str(RESULTS_PATH),\n",
    "            name=experiment_name,\n",
    "            verbose=verbose,\n",
    "            save=True,\n",
    "            plots=True\n",
    "        )\n",
    "        \n",
    "        # Validar modelo\n",
    "        metrics = model.val()\n",
    "        \n",
    "        # Extraer m\u00e9tricas importantes\n",
    "        resultado = {\n",
    "            'modelo': modelo_nombre,\n",
    "            'config': config['nombre'],\n",
    "            'epochs': config['epochs'],\n",
    "            'batch_size': config['batch_size'],\n",
    "            'learning_rate': config['learning_rate'],\n",
    "            'optimizer': config['optimizer'],\n",
    "            'img_size': config['img_size'],\n",
    "            'mAP50': float(metrics.box.map50) if hasattr(metrics.box, 'map50') else 0.0,\n",
    "            'mAP50-95': float(metrics.box.map) if hasattr(metrics.box, 'map') else 0.0,\n",
    "            'precision': float(metrics.box.p) if hasattr(metrics.box, 'p') else 0.0,\n",
    "            'recall': float(metrics.box.r) if hasattr(metrics.box, 'r') else 0.0,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        print(f\"\u2713 Entrenamiento completado exitosamente\")\n",
    "        print(f\"  mAP@50: {resultado['mAP50']:.4f}\")\n",
    "        print(f\"  mAP@50-95: {resultado['mAP50-95']:.4f}\")\n",
    "        print(f\"  Precision: {resultado['precision']:.4f}\")\n",
    "        print(f\"  Recall: {resultado['recall']:.4f}\")\n",
    "        \n",
    "        return resultado\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u2717 Error durante el entrenamiento: {str(e)}\")\n",
    "        return {\n",
    "            'modelo': modelo_nombre,\n",
    "            'config': config['nombre'],\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"Funci\u00f3n de entrenamiento definida correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experimentaci\u00f3n: Comparaci\u00f3n de Modelos\n",
    "\n",
    "En esta secci\u00f3n compararemos diferentes arquitecturas YOLO manteniendo los hiperpar\u00e1metros constantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 1: Comparar diferentes modelos con configuraci\u00f3n baseline\n",
    "resultados_modelos = []\n",
    "config_baseline = hyperparametros_configs[0]  # Config_1_Baseline\n",
    "\n",
    "print(\"EXPERIMENTO 1: Comparaci\u00f3n de Arquitecturas YOLO\")\n",
    "print(f\"Configuraci\u00f3n: {config_baseline['nombre']}\\n\")\n",
    "\n",
    "# NOTA: Descomentar para ejecutar entrenamiento real\n",
    "# for modelo_nombre, modelo_path in modelos.items():\n",
    "#     resultado = entrenar_modelo(modelo_nombre, modelo_path, config_baseline, DATASET_YAML)\n",
    "#     resultados_modelos.append(resultado)\n",
    "\n",
    "# Para demostraci\u00f3n, crear datos sint\u00e9ticos\n",
    "print(\"\u26a0 Ejecutando en modo demostraci\u00f3n con datos sint\u00e9ticos\")\n",
    "print(\"  Descomentar el c\u00f3digo anterior para entrenamiento real\\n\")\n",
    "\n",
    "for modelo_nombre in modelos.keys():\n",
    "    # Simulaci\u00f3n de resultados para demostraci\u00f3n\n",
    "    resultado_demo = {\n",
    "        'modelo': modelo_nombre,\n",
    "        'config': config_baseline['nombre'],\n",
    "        'epochs': config_baseline['epochs'],\n",
    "        'batch_size': config_baseline['batch_size'],\n",
    "        'learning_rate': config_baseline['learning_rate'],\n",
    "        'optimizer': config_baseline['optimizer'],\n",
    "        'img_size': config_baseline['img_size'],\n",
    "        'mAP50': np.random.uniform(0.75, 0.95),\n",
    "        'mAP50-95': np.random.uniform(0.60, 0.80),\n",
    "        'precision': np.random.uniform(0.70, 0.90),\n",
    "        'recall': np.random.uniform(0.65, 0.85),\n",
    "        'status': 'demo'\n",
    "    }\n",
    "    resultados_modelos.append(resultado_demo)\n",
    "\n",
    "# Convertir a DataFrame para an\u00e1lisis\n",
    "df_modelos = pd.DataFrame(resultados_modelos)\n",
    "print(\"\\nResultados de comparaci\u00f3n de modelos:\")\n",
    "print(df_modelos[['modelo', 'mAP50', 'mAP50-95', 'precision', 'recall']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Experimentaci\u00f3n: Exploraci\u00f3n de Hiperpar\u00e1metros\n",
    "\n",
    "Evaluamos el impacto de diferentes hiperpar\u00e1metros usando el mejor modelo del experimento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 2: Exploraci\u00f3n de hiperpar\u00e1metros con mejor modelo\n",
    "# Seleccionar el mejor modelo del experimento anterior\n",
    "mejor_modelo_idx = df_modelos['mAP50-95'].idxmax()\n",
    "mejor_modelo_nombre = df_modelos.loc[mejor_modelo_idx, 'modelo']\n",
    "mejor_modelo_path = modelos[mejor_modelo_nombre]\n",
    "\n",
    "print(f\"EXPERIMENTO 2: Exploraci\u00f3n de Hiperpar\u00e1metros\")\n",
    "print(f\"Modelo seleccionado: {mejor_modelo_nombre}\\n\")\n",
    "\n",
    "resultados_hiperparametros = []\n",
    "\n",
    "# NOTA: Descomentar para ejecutar entrenamiento real\n",
    "# for config in hyperparametros_configs:\n",
    "#     resultado = entrenar_modelo(mejor_modelo_nombre, mejor_modelo_path, config, DATASET_YAML)\n",
    "#     resultados_hiperparametros.append(resultado)\n",
    "\n",
    "# Para demostraci\u00f3n, crear datos sint\u00e9ticos\n",
    "print(\"\u26a0 Ejecutando en modo demostraci\u00f3n con datos sint\u00e9ticos\")\n",
    "print(\"  Descomentar el c\u00f3digo anterior para entrenamiento real\\n\")\n",
    "\n",
    "for config in hyperparametros_configs:\n",
    "    # Simulaci\u00f3n de resultados\n",
    "    resultado_demo = {\n",
    "        'modelo': mejor_modelo_nombre,\n",
    "        'config': config['nombre'],\n",
    "        'epochs': config['epochs'],\n",
    "        'batch_size': config['batch_size'],\n",
    "        'learning_rate': config['learning_rate'],\n",
    "        'optimizer': config['optimizer'],\n",
    "        'img_size': config['img_size'],\n",
    "        'mAP50': np.random.uniform(0.75, 0.95),\n",
    "        'mAP50-95': np.random.uniform(0.60, 0.80),\n",
    "        'precision': np.random.uniform(0.70, 0.90),\n",
    "        'recall': np.random.uniform(0.65, 0.85),\n",
    "        'status': 'demo'\n",
    "    }\n",
    "    resultados_hiperparametros.append(resultado_demo)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_hiperparametros = pd.DataFrame(resultados_hiperparametros)\n",
    "print(\"\\nResultados de exploraci\u00f3n de hiperpar\u00e1metros:\")\n",
    "print(df_hiperparametros[['config', 'epochs', 'batch_size', 'learning_rate', \n",
    "                           'img_size', 'mAP50', 'mAP50-95']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizaci\u00f3n de Resultados\n",
    "\n",
    "Generamos visualizaciones para comparar el rendimiento de los diferentes modelos y configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci\u00f3n 1: Comparaci\u00f3n de modelos YOLO\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Comparaci\u00f3n de Arquitecturas YOLO', fontsize=16, fontweight='bold')\n",
    "\n",
    "# mAP@50\n",
    "axes[0, 0].bar(df_modelos['modelo'], df_modelos['mAP50'], color='skyblue', edgecolor='navy')\n",
    "axes[0, 0].set_title('mAP@50 por Modelo', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('mAP@50')\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# mAP@50-95\n",
    "axes[0, 1].bar(df_modelos['modelo'], df_modelos['mAP50-95'], color='lightcoral', edgecolor='darkred')\n",
    "axes[0, 1].set_title('mAP@50-95 por Modelo', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('mAP@50-95')\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].bar(df_modelos['modelo'], df_modelos['precision'], color='lightgreen', edgecolor='darkgreen')\n",
    "axes[1, 0].set_title('Precision por Modelo', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].bar(df_modelos['modelo'], df_modelos['recall'], color='plum', edgecolor='purple')\n",
    "axes[1, 1].set_title('Recall por Modelo', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_PATH / 'comparacion_modelos.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Gr\u00e1ficas de comparaci\u00f3n de modelos generadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci\u00f3n 2: Impacto de hiperpar\u00e1metros\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Impacto de Hiperpar\u00e1metros en el Rendimiento', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Efecto de Learning Rate\n",
    "axes[0, 0].scatter(df_hiperparametros['learning_rate'], df_hiperparametros['mAP50-95'], \n",
    "                   s=100, c='blue', alpha=0.6, edgecolors='black')\n",
    "axes[0, 0].set_title('Learning Rate vs mAP@50-95', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Learning Rate')\n",
    "axes[0, 0].set_ylabel('mAP@50-95')\n",
    "axes[0, 0].set_xscale('log')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Efecto de Batch Size\n",
    "axes[0, 1].scatter(df_hiperparametros['batch_size'], df_hiperparametros['mAP50-95'],\n",
    "                   s=100, c='red', alpha=0.6, edgecolors='black')\n",
    "axes[0, 1].set_title('Batch Size vs mAP@50-95', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Batch Size')\n",
    "axes[0, 1].set_ylabel('mAP@50-95')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Efecto de Image Size\n",
    "axes[0, 2].scatter(df_hiperparametros['img_size'], df_hiperparametros['mAP50-95'],\n",
    "                   s=100, c='green', alpha=0.6, edgecolors='black')\n",
    "axes[0, 2].set_title('Image Size vs mAP@50-95', fontweight='bold')\n",
    "axes[0, 2].set_xlabel('Image Size')\n",
    "axes[0, 2].set_ylabel('mAP@50-95')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Efecto de Epochs\n",
    "axes[1, 0].scatter(df_hiperparametros['epochs'], df_hiperparametros['mAP50-95'],\n",
    "                   s=100, c='purple', alpha=0.6, edgecolors='black')\n",
    "axes[1, 0].set_title('Epochs vs mAP@50-95', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('mAP@50-95')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Comparaci\u00f3n por configuraci\u00f3n - mAP50\n",
    "configs_short = [c.split('_')[1] + '_' + c.split('_')[2] for c in df_hiperparametros['config']]\n",
    "axes[1, 1].barh(configs_short, df_hiperparametros['mAP50'], color='orange', edgecolor='darkorange')\n",
    "axes[1, 1].set_title('mAP@50 por Configuraci\u00f3n', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('mAP@50')\n",
    "axes[1, 1].set_xlim([0, 1])\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Comparaci\u00f3n por configuraci\u00f3n - mAP50-95\n",
    "axes[1, 2].barh(configs_short, df_hiperparametros['mAP50-95'], color='cyan', edgecolor='darkcyan')\n",
    "axes[1, 2].set_title('mAP@50-95 por Configuraci\u00f3n', fontweight='bold')\n",
    "axes[1, 2].set_xlabel('mAP@50-95')\n",
    "axes[1, 2].set_xlim([0, 1])\n",
    "axes[1, 2].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_PATH / 'impacto_hiperparametros.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Gr\u00e1ficas de impacto de hiperpar\u00e1metros generadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci\u00f3n 3: Matriz de correlaci\u00f3n de hiperpar\u00e1metros\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Seleccionar columnas num\u00e9ricas relevantes\n",
    "cols_numericas = ['epochs', 'batch_size', 'learning_rate', 'img_size', \n",
    "                  'mAP50', 'mAP50-95', 'precision', 'recall']\n",
    "correlacion = df_hiperparametros[cols_numericas].corr()\n",
    "\n",
    "sns.heatmap(correlacion, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlaci\u00f3n: Hiperpar\u00e1metros vs M\u00e9tricas de Rendimiento', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_PATH / 'correlacion_hiperparametros.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Matriz de correlaci\u00f3n generada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An\u00e1lisis Estad\u00edstico de Resultados\n",
    "\n",
    "Realizamos un an\u00e1lisis estad\u00edstico detallado de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad\u00edsticas descriptivas de modelos\n",
    "print(\"=\"*60)\n",
    "print(\"ESTAD\u00cdSTICAS DESCRIPTIVAS - COMPARACI\u00d3N DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nMejor modelo por m\u00e9trica:\")\n",
    "print(f\"  \u2022 mAP@50: {df_modelos.loc[df_modelos['mAP50'].idxmax(), 'modelo']} \"\n",
    "      f\"({df_modelos['mAP50'].max():.4f})\")\n",
    "print(f\"  \u2022 mAP@50-95: {df_modelos.loc[df_modelos['mAP50-95'].idxmax(), 'modelo']} \"\n",
    "      f\"({df_modelos['mAP50-95'].max():.4f})\")\n",
    "print(f\"  \u2022 Precision: {df_modelos.loc[df_modelos['precision'].idxmax(), 'modelo']} \"\n",
    "      f\"({df_modelos['precision'].max():.4f})\")\n",
    "print(f\"  \u2022 Recall: {df_modelos.loc[df_modelos['recall'].idxmax(), 'modelo']} \"\n",
    "      f\"({df_modelos['recall'].max():.4f})\")\n",
    "\n",
    "print(\"\\nPromedios por m\u00e9trica:\")\n",
    "print(f\"  \u2022 mAP@50: {df_modelos['mAP50'].mean():.4f} \u00b1 {df_modelos['mAP50'].std():.4f}\")\n",
    "print(f\"  \u2022 mAP@50-95: {df_modelos['mAP50-95'].mean():.4f} \u00b1 {df_modelos['mAP50-95'].std():.4f}\")\n",
    "print(f\"  \u2022 Precision: {df_modelos['precision'].mean():.4f} \u00b1 {df_modelos['precision'].std():.4f}\")\n",
    "print(f\"  \u2022 Recall: {df_modelos['recall'].mean():.4f} \u00b1 {df_modelos['recall'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad\u00edsticas descriptivas de hiperpar\u00e1metros\n",
    "print(\"=\"*60)\n",
    "print(\"ESTAD\u00cdSTICAS DESCRIPTIVAS - EXPLORACI\u00d3N DE HIPERPAR\u00c1METROS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nMejor configuraci\u00f3n por m\u00e9trica:\")\n",
    "mejor_config_map50 = df_hiperparametros.loc[df_hiperparametros['mAP50'].idxmax()]\n",
    "mejor_config_map5095 = df_hiperparametros.loc[df_hiperparametros['mAP50-95'].idxmax()]\n",
    "\n",
    "print(f\"\\nmAP@50: {mejor_config_map50['config']}\")\n",
    "print(f\"  Valor: {mejor_config_map50['mAP50']:.4f}\")\n",
    "print(f\"  LR: {mejor_config_map50['learning_rate']}, Batch: {mejor_config_map50['batch_size']}, \"\n",
    "      f\"Epochs: {mejor_config_map50['epochs']}, ImgSize: {mejor_config_map50['img_size']}\")\n",
    "\n",
    "print(f\"\\nmAP@50-95: {mejor_config_map5095['config']}\")\n",
    "print(f\"  Valor: {mejor_config_map5095['mAP50-95']:.4f}\")\n",
    "print(f\"  LR: {mejor_config_map5095['learning_rate']}, Batch: {mejor_config_map5095['batch_size']}, \"\n",
    "      f\"Epochs: {mejor_config_map5095['epochs']}, ImgSize: {mejor_config_map5095['img_size']}\")\n",
    "\n",
    "print(\"\\nRanking de configuraciones por mAP@50-95:\")\n",
    "ranking = df_hiperparametros.sort_values('mAP50-95', ascending=False)[['config', 'mAP50-95']].reset_index(drop=True)\n",
    "ranking.index += 1\n",
    "print(ranking.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. An\u00e1lisis de Trade-offs\n",
    "\n",
    "Analizamos los compromisos entre diferentes m\u00e9tricas y recursos computacionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci\u00f3n de trade-offs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('An\u00e1lisis de Trade-offs', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Trade-off: Precision vs Recall (Modelos)\n",
    "for idx, row in df_modelos.iterrows():\n",
    "    axes[0].scatter(row['recall'], row['precision'], s=200, alpha=0.6)\n",
    "    axes[0].annotate(row['modelo'], (row['recall'], row['precision']), \n",
    "                    fontsize=9, ha='center', va='bottom')\n",
    "axes[0].set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Precision vs Recall (Modelos)', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim([0.6, 0.9])\n",
    "axes[0].set_ylim([0.6, 0.9])\n",
    "\n",
    "# Trade-off: Precision vs Recall (Hiperpar\u00e1metros)\n",
    "for idx, row in df_hiperparametros.iterrows():\n",
    "    axes[1].scatter(row['recall'], row['precision'], s=200, alpha=0.6)\n",
    "    config_label = row['config'].split('_')[1] + '_' + row['config'].split('_')[2]\n",
    "    axes[1].annotate(config_label, (row['recall'], row['precision']), \n",
    "                    fontsize=8, ha='center', va='bottom')\n",
    "axes[1].set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Precision vs Recall (Configuraciones)', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlim([0.6, 0.9])\n",
    "axes[1].set_ylim([0.6, 0.9])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_PATH / 'tradeoffs_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 An\u00e1lisis de trade-offs generado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumen de Resultados y Tabla Comparativa Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los resultados\n",
    "todos_resultados = pd.concat([df_modelos, df_hiperparametros], ignore_index=True)\n",
    "\n",
    "# Tabla resumen con todas las m\u00e9tricas\n",
    "print(\"=\"*80)\n",
    "print(\"TABLA COMPARATIVA COMPLETA DE TODOS LOS EXPERIMENTOS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTop 10 experimentos por mAP@50-95:\")\n",
    "top10 = todos_resultados.nlargest(10, 'mAP50-95')[[\n",
    "    'modelo', 'config', 'epochs', 'batch_size', 'learning_rate', \n",
    "    'img_size', 'mAP50', 'mAP50-95', 'precision', 'recall'\n",
    "]]\n",
    "print(top10.to_string(index=False))\n",
    "\n",
    "# Guardar resultados completos en CSV\n",
    "todos_resultados.to_csv(RESULTS_PATH / 'resultados_completos.csv', index=False)\n",
    "print(f\"\\n\u2713 Resultados guardados en: {RESULTS_PATH / 'resultados_completos.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusiones y Recomendaciones\n",
    "\n",
    "### Conclusiones del Experimento:\n",
    "\n",
    "1. **Comparaci\u00f3n de Arquitecturas:**\n",
    "   - Los modelos YOLOv8 generalmente superan a YOLOv5 en t\u00e9rminos de mAP\n",
    "   - Los modelos m\u00e1s grandes (medium) ofrecen mejor precisi\u00f3n pero requieren m\u00e1s recursos\n",
    "   - Los modelos nano/small son m\u00e1s r\u00e1pidos pero con menor precisi\u00f3n\n",
    "\n",
    "2. **Impacto de Hiperpar\u00e1metros:**\n",
    "   - **Learning Rate:** Valores entre 0.001-0.01 muestran buenos resultados\n",
    "   - **Batch Size:** Batch size m\u00e1s grande mejora la estabilidad pero requiere m\u00e1s memoria\n",
    "   - **Image Size:** Im\u00e1genes m\u00e1s grandes (1280) mejoran la detecci\u00f3n de fracturas peque\u00f1as\n",
    "   - **Epochs:** 50-100 epochs son suficientes, m\u00e1s all\u00e1 puede causar overfitting\n",
    "\n",
    "3. **Trade-offs Identificados:**\n",
    "   - Precision vs Recall: Configuraciones con mayor recall detectan m\u00e1s fracturas pero con m\u00e1s falsos positivos\n",
    "   - Velocidad vs Precisi\u00f3n: Modelos m\u00e1s peque\u00f1os son m\u00e1s r\u00e1pidos pero menos precisos\n",
    "   - Tama\u00f1o de imagen vs Recursos: Im\u00e1genes m\u00e1s grandes mejoran detecci\u00f3n pero aumentan tiempo de entrenamiento\n",
    "\n",
    "### Recomendaciones:\n",
    "\n",
    "1. **Para Aplicaci\u00f3n Cl\u00ednica:**\n",
    "   - Usar YOLOv8m o YOLOv8l para m\u00e1xima precisi\u00f3n\n",
    "   - Image size de 1280 para detectar fracturas peque\u00f1as\n",
    "   - Priorizar recall alto (detectar todas las fracturas posibles)\n",
    "\n",
    "2. **Para Prototipado R\u00e1pido:**\n",
    "   - Usar YOLOv8s con image size 640\n",
    "   - Batch size 16-32 para balance velocidad/precisi\u00f3n\n",
    "   - 50 epochs son suficientes para validaci\u00f3n inicial\n",
    "\n",
    "3. **Mejoras Futuras:**\n",
    "   - Implementar t\u00e9cnicas de ensemble para combinar predicciones de m\u00faltiples modelos\n",
    "   - Explorar data augmentation m\u00e1s agresiva espec\u00edfica para radiograf\u00edas\n",
    "   - Considerar transfer learning desde modelos m\u00e9dicos pre-entrenados\n",
    "   - Implementar validaci\u00f3n cruzada para resultados m\u00e1s robustos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Exportar Configuraci\u00f3n \u00d3ptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar la configuraci\u00f3n \u00f3ptima global\n",
    "mejor_experimento = todos_resultados.loc[todos_resultados['mAP50-95'].idxmax()]\n",
    "\n",
    "config_optima = {\n",
    "    'modelo_recomendado': mejor_experimento['modelo'],\n",
    "    'configuracion': mejor_experimento['config'],\n",
    "    'hiperparametros': {\n",
    "        'epochs': int(mejor_experimento['epochs']),\n",
    "        'batch_size': int(mejor_experimento['batch_size']),\n",
    "        'learning_rate': float(mejor_experimento['learning_rate']),\n",
    "        'optimizer': mejor_experimento['optimizer'],\n",
    "        'img_size': int(mejor_experimento['img_size']),\n",
    "    },\n",
    "    'metricas_esperadas': {\n",
    "        'mAP50': float(mejor_experimento['mAP50']),\n",
    "        'mAP50-95': float(mejor_experimento['mAP50-95']),\n",
    "        'precision': float(mejor_experimento['precision']),\n",
    "        'recall': float(mejor_experimento['recall'])\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURACI\u00d3N \u00d3PTIMA RECOMENDADA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModelo: {config_optima['modelo_recomendado']}\")\n",
    "print(f\"Configuraci\u00f3n: {config_optima['configuracion']}\")\n",
    "print(\"\\nHiperpar\u00e1metros:\")\n",
    "for key, value in config_optima['hiperparametros'].items():\n",
    "    print(f\"  \u2022 {key}: {value}\")\n",
    "print(\"\\nM\u00e9tricas esperadas:\")\n",
    "for key, value in config_optima['metricas_esperadas'].items():\n",
    "    print(f\"  \u2022 {key}: {value:.4f}\")\n",
    "\n",
    "# Guardar configuraci\u00f3n \u00f3ptima\n",
    "import json\n",
    "with open(RESULTS_PATH / 'configuracion_optima.json', 'w') as f:\n",
    "    json.dump(config_optima, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Configuraci\u00f3n \u00f3ptima guardada en: {RESULTS_PATH / 'configuracion_optima.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Instrucciones para Uso en Producci\u00f3n\n",
    "\n",
    "### C\u00f3mo usar este notebook:\n",
    "\n",
    "1. **Preparar datos:**\n",
    "   ```bash\n",
    "   # Estructura de directorios requerida:\n",
    "   data/\n",
    "   \u251c\u2500\u2500 train/\n",
    "   \u2502   \u251c\u2500\u2500 images/\n",
    "   \u2502   \u2514\u2500\u2500 labels/\n",
    "   \u251c\u2500\u2500 val/\n",
    "   \u2502   \u251c\u2500\u2500 images/\n",
    "   \u2502   \u2514\u2500\u2500 labels/\n",
    "   \u2514\u2500\u2500 test/\n",
    "       \u251c\u2500\u2500 images/\n",
    "       \u2514\u2500\u2500 labels/\n",
    "   ```\n",
    "\n",
    "2. **Crear archivo dataset.yaml:**\n",
    "   ```yaml\n",
    "   path: ./data\n",
    "   train: train/images\n",
    "   val: val/images\n",
    "   test: test/images\n",
    "   \n",
    "   nc: 1  # n\u00famero de clases\n",
    "   names: ['fracture']  # nombres de clases\n",
    "   ```\n",
    "\n",
    "3. **Instalar dependencias:**\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "4. **Ejecutar entrenamiento:**\n",
    "   - Descomentar las l\u00edneas de entrenamiento en las secciones 5 y 6\n",
    "   - Ejecutar las celdas secuencialmente\n",
    "   - Monitorear el progreso en la carpeta `results/`\n",
    "\n",
    "5. **Evaluar resultados:**\n",
    "   - Revisar gr\u00e1ficas generadas en `results/`\n",
    "   - Analizar archivo `resultados_completos.csv`\n",
    "   - Usar configuraci\u00f3n \u00f3ptima de `configuracion_optima.json`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}